{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi-JBqaijhJa"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.6.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi[unidic-lite]\n"
      ],
      "metadata": {
        "id": "GG7aKPj-jvBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n"
      ],
      "metadata": {
        "id": "docXAqchjx1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#english\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "id": "MOW1odrOk9oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#japanese\n",
        "!python -m spacy download ja_core_news_sm\n"
      ],
      "metadata": {
        "id": "6jaoczx2lAoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chinese,arabic,russian\n",
        "!python -m spacy download zh_core_web_sm\n",
        "!python -m spacy download xx_ent_wiki_sm\n",
        "!python -m spacy download ru_core_news_sm\n",
        "\n"
      ],
      "metadata": {
        "id": "MEAWjx9lmnFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset pth\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "path = \"/content/normalization_assesment_dataset_10k.csv\"\n",
        "df = pd.read_csv(path, usecols=[0,1], header=0)"
      ],
      "metadata": {
        "id": "LdDXQGyAlKRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import spacy\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset"
      ],
      "metadata": {
        "id": "ahfy6uX9ndM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torchtext.data import Field, TabularDataset"
      ],
      "metadata": {
        "id": "CHPTPqIFsSIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "ZzhwUFJXsUyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tokenization function\n",
        "def tokenize_text(text):\n",
        "    #tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "HyMrWc4Hslxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating fields\n",
        "SRC = Field(tokenize=tokenize_text,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=False)\n",
        "\n",
        "TRG = Field(tokenize=tokenize_text,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=False)"
      ],
      "metadata": {
        "id": "gt_n_aWBtLrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_fields = [('src', SRC), ('trg', TRG)]"
      ],
      "metadata": {
        "id": "WSeiUGoMtf8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV file\n",
        "input_file = '/content/normalization_assesment_dataset_10k.csv'  # Replace with the path to your input file\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Ensure the dataframe has the correct number of rows (10,000)\n",
        "assert len(df) == 10000, \"The CSV file must have exactly 10,000 rows\"\n",
        "\n",
        "# Split the dataframe into the three parts\n",
        "train_df = df.iloc[:5000]\n",
        "test_df = df.iloc[5000:7500]\n",
        "valid_df = df.iloc[7500:10000]\n",
        "\n",
        "# Save each part as a new CSV\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "valid_df.to_csv('valid.csv', index=False)\n",
        "\n",
        "print(\"CSV files split and saved successfully!\")\n"
      ],
      "metadata": {
        "id": "H96aJuqpubh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "UX1P5P30vmkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into train, validation, and test sets\n",
        "train, val, test = TabularDataset.splits(\n",
        "    path='./',\n",
        "    train='train.csv',\n",
        "    validation='valid.csv',\n",
        "    test='test.csv',\n",
        "    format='csv',\n",
        "    fields=data_fields,  # Specify the fields mapping\n",
        "    skip_header=True\n",
        ")\n",
        "\n",
        "# Check the first example in the training data\n",
        "print(vars(train.examples[0]))\n",
        "\n",
        "# Check the length of the datasets\n",
        "print(f\"Train dataset size: {len(train.examples)}\")\n",
        "print(f\"Validation dataset size: {len(val.examples)}\")\n",
        "print(f\"Test dataset size: {len(test.examples)}\")\n",
        "\n",
        "# Build vocabulary for SRC and TRG using the training dataset\n",
        "SRC.build_vocab(train, min_freq=2)  # Set min_freq as needed to filter rare tokens\n",
        "TRG.build_vocab(train, min_freq=2)\n",
        "\n",
        "# Print the vocabulary sizes\n",
        "print(f\"Source vocabulary size: {len(SRC.vocab)}\")\n",
        "print(f\"Target vocabulary size: {len(TRG.vocab)}\")"
      ],
      "metadata": {
        "id": "syNCezKEtna9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.examples[0])\n"
      ],
      "metadata": {
        "id": "-LedXJGtv4VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train.examples), len(val.examples), len(test.examples)\n"
      ],
      "metadata": {
        "id": "o7fRKjf2v8Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ],
      "metadata": {
        "id": "KhwFRboRwTQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(SRC.vocab))\n",
        "print(len(TRG.vocab))"
      ],
      "metadata": {
        "id": "XkIeur0yyF1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "aAD5WdItyJ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 20\n",
        "\n",
        "train_iter = BucketIterator(\n",
        "    train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device = device\n",
        ")\n",
        "\n",
        "valid_iter = BucketIterator(\n",
        "    val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device = device\n",
        ")\n",
        "\n",
        "test_iter = BucketIterator(\n",
        "    test,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "O5q8vTnmyTlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder of seq2seq model\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        #src = [src len, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "hZG_8gN-yX7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder of the seq2seq model\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "      #input = [1, batch size]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        #prediction = [batch size, output dim]\n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "i6MvKiFuycTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "nKQf6UQAy2sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "metadata": {
        "id": "oDRgYTzIzEdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "oAoT5JR8zKa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "qzGTTsQ8zPC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "FTn7cmeBzSdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "6zvBIZnb0V9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip =1):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "\n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "2VAqZ_tz0aGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src   #src!\n",
        "            trg = batch.trg    #trg!\n",
        "            output = model(src, trg, 0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "i1zyeLmZ0jwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "1fKjG0yf23ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 15  # train for 15 epochs\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model,\n",
        "              train_iter,\n",
        "              optimizer,\n",
        "              criterion)\n",
        "    valid_loss = evaluate(model,\n",
        "              valid_iter,\n",
        "              criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "sk5Xb7TU28g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "metadata": {
        "id": "sgAH4kov32cA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n"
      ],
      "metadata": {
        "id": "LaN7TV2l665n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n"
      ],
      "metadata": {
        "id": "N1v1os327EG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import spacy\n",
        "import langdetect  # To detect language\n",
        "import jieba  # For Chinese tokenization\n",
        "import stanza  # For Russian, Arabic, and other languages\n",
        "\n",
        "# Load spaCy models for different languages\n",
        "spacy_en = spacy.load('en_core_web_sm')  # English tokenizer\n",
        "spacy_zh = spacy.load('zh_core_web_sm')  # Chinese tokenizer\n",
        "spacy_ar = spacy.load('xx_ent_wiki_sm')  # A multilingual tokenizer for Arabic, etc.\n",
        "# For Russian and other languages\n",
        "stanza_ru = stanza.Pipeline(lang='ru', processors='tokenize')\n",
        "stanza_ar = stanza.Pipeline(lang='ar', processors='tokenize')\n",
        "\n",
        "# Function to detect language\n",
        "def detect_language(text):\n",
        "    return langdetect.detect(text)\n",
        "\n",
        "def normalize_sentence(sentence, src_field, trg_field, model, device, max_len=50):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # If the input sentence is a list of tokens, join them into a single string\n",
        "    if isinstance(sentence, list):\n",
        "        sentence = ' '.join(sentence)  # Join the list of tokens into a string\n",
        "\n",
        "    # Detect the language of the input sentence (now it's a string)\n",
        "    language = detect_language(sentence)\n",
        "\n",
        "    # Tokenize based on language\n",
        "    if language == 'en':  # English\n",
        "        nlp = spacy_en\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "    elif language == 'zh':  # Chinese\n",
        "        tokens = list(jieba.cut(sentence))\n",
        "    elif language == 'ru':  # Russian\n",
        "        doc = stanza_ru(sentence)\n",
        "        tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
        "    elif language == 'ar':  # Arabic\n",
        "        doc = stanza_ar(sentence)\n",
        "        tokens = [word.text for sent in doc.sentences for word in sent.words]\n",
        "    else:  # Other languages\n",
        "        nlp = spacy_zh  # Using a multilingual model for unsupported languages\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "\n",
        "    # Debugging step: print tokenized sentence\n",
        "    print(f\"Tokenized sentence: {tokens}\")\n",
        "\n",
        "    # Add start and end tokens\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "\n",
        "    # Convert tokens to their index representations in the vocabulary\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    # Pass the source tensor through the encoder\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    # Initialize the target sequence with the <sos> token\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    # Generate output sequence step by step\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "\n",
        "        # Get the predicted token (index)\n",
        "        pred_token = output.argmax(1).item()\n",
        "\n",
        "        # Append the predicted token to the target sequence\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        # Stop if we reach the <eos> token\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "\n",
        "    # Convert the indices back to tokens (the predicted normalized text)\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    # Return the normalized sentence, removing <sos> and <eos> tokens\n",
        "    return trg_tokens[1:-1]  # Removing <sos> and <eos> when returning the output\n",
        "\n"
      ],
      "metadata": {
        "id": "OxWULE5HmdPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    for datum in data:\n",
        "\n",
        "        src = vars(datum)['src']\n",
        "        trg = vars(datum)['trg']\n",
        "\n",
        "        pred_trg = normalize_sentence(src, src_field, trg_field, model, device, max_len)\n",
        "\n",
        "        #cut off <eos> token\n",
        "        #pred_trg = pred_trg[:-1]\n",
        "\n",
        "        pred_trgs.append(pred_trg)\n",
        "        trgs.append([trg])\n",
        "\n",
        "    return bleu_score(pred_trgs, trgs)"
      ],
      "metadata": {
        "id": "UATCxTmp7Sk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_value = calculate_bleu(test, SRC, TRG, model, device)\n",
        "\n",
        "print(f'BLEU score = {bleu_value*100:.2f}')"
      ],
      "metadata": {
        "id": "68VSGbZeOteY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}